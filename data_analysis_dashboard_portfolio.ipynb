{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06a5acd7",
   "metadata": {},
   "source": [
    "# Data Analysis RAG Dashboard (Streamlit Version)\n",
    "\n",
    "This notebook is a portfolio version of the Streamlit application for data analysis.\n",
    "Each step is explained in markdown so that reviewers on GitHub can understand it.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd0fce9",
   "metadata": {},
   "source": [
    "## 1. Import Library and Setup\n",
    "We start by importing the libraries used in the original Streamlit application, including pandas, numpy, seaborn, matplotlib, statsmodels, and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26934a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import openai\n",
    "from fpdf import FPDF\n",
    "import tempfile\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c24f07",
   "metadata": {},
   "source": [
    "## 2. Column Type Detection Function\n",
    "The `detect_col_type` function will automatically detect which columns are numeric, categorical, or date-based, to facilitate automatic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffa39f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_col_type(df):\n",
    "    dtypes = {}\n",
    "    force_numeric = ['bounce_flag', 'revenue_$', 'conversion_flag',\n",
    "                     'pages_visited', 'time_spent', 'demographic_age']\n",
    "    for c in df.columns:\n",
    "        series = df[c]\n",
    "        if c.lower() in [f.lower() for f in force_numeric]:\n",
    "            dtypes[c] = 'numeric'\n",
    "            continue\n",
    "        name_hint = any(x in c.lower() for x in ['date', 'timestamp'])\n",
    "        looks_like_date = series.astype(str).str.contains(r'[-/:]').mean() > 0.5\n",
    "        if name_hint or looks_like_date:\n",
    "            try:\n",
    "                parsed = pd.to_datetime(series, errors='coerce', infer_datetime_format=True)\n",
    "                if parsed.notna().sum() > len(series) * 0.5:\n",
    "                    df[c] = parsed\n",
    "                    dtypes[c] = 'date'\n",
    "                    continue\n",
    "            except:\n",
    "                pass\n",
    "        if pd.api.types.is_numeric_dtype(series):\n",
    "            dtypes[c] = 'numeric'\n",
    "        else:\n",
    "            dtypes[c] = 'categorical'\n",
    "    return dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fed078",
   "metadata": {},
   "source": [
    "## 3. Statistical Test Functions\n",
    "Includes automatic detection of T-tests, Mann-Whitney tests, ANOVA/Kruskal tests, regression tests, and Chi-Square tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef245319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_test(df, grp, val):\n",
    "    groups = df[grp].dropna().unique()\n",
    "    vals = [df[df[grp]==g][val].dropna() for g in groups]\n",
    "    normal = all(stats.shapiro(v)[1] > 0.05 for v in vals if len(v)>=3)\n",
    "    eq = stats.levene(*vals)[1] > 0.05\n",
    "    if len(groups)==2:\n",
    "        return \"t-test\" if normal and eq else \"mann-whitney\"\n",
    "    return \"anova\" if normal and eq else \"kruskal\"\n",
    "\n",
    "def run_tests(df, grp, val):\n",
    "    test = detect_test(df, grp, val)\n",
    "    if test in [\"t-test\", \"mann-whitney\"]:\n",
    "        g = df[grp].dropna().unique()\n",
    "        a,b = df[df[grp]==g[0]][val], df[df[grp]==g[1]][val]\n",
    "        if test==\"t-test\":\n",
    "            t,p = stats.ttest_ind(a,b)\n",
    "            return f\"T-test: t={t:.3f}, p={p:.4f}\", test\n",
    "        else:\n",
    "            u,p = stats.mannwhitneyu(a,b)\n",
    "            return f\"Mann-Whitney U={u:.3f}, p={p:.4f}\", test\n",
    "    elif test==\"anova\":\n",
    "        model = ols(f'{val} ~ C({grp})', df).fit()\n",
    "        aov = sm.stats.anova_lm(model, typ=2)\n",
    "        tuk = pairwise_tukeyhsd(df[val], df[grp])\n",
    "        return f\"ANOVA:\\n{aov}\\n\\nTukey HSD:\\n{tuk.summary()}\", test\n",
    "    else:\n",
    "        vals = [df[df[grp]==g][val] for g in df[grp].unique()]\n",
    "        h,p = stats.kruskal(*vals)\n",
    "        return f\"Kruskal-Wallis H={h:.3f}, p={p:.4f}\", test\n",
    "\n",
    "def run_chi2(df, col1, col2):\n",
    "    tab = pd.crosstab(df[col1], df[col2])\n",
    "    chi, p, _, _ = stats.chi2_contingency(tab)\n",
    "    return f\"Chi-Square: χ²={chi:.3f}, p={p:.4f}\", chi, p\n",
    "\n",
    "def run_regression(df, y, x):\n",
    "    y_data = df[y]\n",
    "    X_data = df[x]\n",
    "    if not pd.api.types.is_numeric_dtype(y_data):\n",
    "        le_y = LabelEncoder()\n",
    "        y_data = le_y.fit_transform(y_data)\n",
    "    for col in x:\n",
    "        if not pd.api.types.is_numeric_dtype(df[col]):\n",
    "            le_x = LabelEncoder()\n",
    "            X_data[col] = le_x.fit_transform(df[col])\n",
    "    X = sm.add_constant(X_data)\n",
    "    if len(np.unique(y_data)) == 2:\n",
    "        model = sm.Logit(y_data, X).fit(disp=False)\n",
    "    else:\n",
    "        model = sm.OLS(y_data, X).fit()\n",
    "    return model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe5dc3b",
   "metadata": {},
   "source": [
    "## 4. Analisis Power (Sample Size Estimation)\n",
    "This section calculates the sample size per group based on Cohen's d, before the user performs statistical tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3ddeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.power import TTestIndPower\n",
    "n = TTestIndPower().solve_power(effect_size=eff, alpha=0.05, power=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28953982",
   "metadata": {},
   "source": [
    "## 5. Main Analysis (Statistical Test)\n",
    "Users can select targets and predictors, and the system will automatically select the appropriate statistical test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b9122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.markdown(\"## 5. Main Statistical Analysis (Statistical Test)\")\n",
    "\n",
    "col1 = st.selectbox(\"Target Column (Dependent Variable)\", df.columns)\n",
    "col2 = st.selectbox(\"Group/Predictor Column (Independent Variable)\", df.columns)\n",
    "\n",
    "target_type = dtypes[col1]\n",
    "group_type = dtypes[col2]\n",
    "\n",
    "# Tentukan uji otomatis berdasarkan tipe data\n",
    "default_test = \"Regression\"\n",
    "if target_type == 'numeric' and group_type == 'categorical':\n",
    "    n_groups = df[col2].nunique()\n",
    "    default_test = \"T-test / Mann-Whitney\" if n_groups == 2 else \"ANOVA / Kruskal-Wallis\"\n",
    "elif target_type == 'categorical' and group_type == 'categorical':\n",
    "    default_test = \"Chi-Square\"\n",
    "\n",
    "test_choice = st.selectbox(\n",
    "    \"Choose Statistical Test (auto-selected)\",\n",
    "    [\"T-test\", \"Mann-Whitney\", \"ANOVA\", \"Kruskal-Wallis\", \"Chi-Square\", \"Regression\"],\n",
    "    index=[\"T-test\", \"Mann-Whitney\", \"ANOVA\", \"Kruskal-Wallis\", \"Chi-Square\", \"Regression\"].index(default_test.split()[0])\n",
    ")\n",
    "\n",
    "st.info(f\"Auto-selected: **{default_test}** (Target: {col1} [{target_type}], Group: {col2} [{group_type}])\")\n",
    "\n",
    "# Jalankan analisis ketika tombol ditekan\n",
    "if st.button(\"Run Analysis\", use_container_width=True):\n",
    "    if test_choice in [\"T-test\", \"Mann-Whitney\", \"ANOVA\", \"Kruskal-Wallis\"] and target_type == 'numeric' and group_type == 'categorical':\n",
    "        res, test = run_tests(df, col2, col1)\n",
    "        insight = explain(res)\n",
    "        save_result('Statistical Test', text=res, insight=insight)\n",
    "\n",
    "    elif test_choice == \"Chi-Square\" and target_type == 'categorical' and group_type == 'categorical':\n",
    "        res, chi, p = run_chi2(df, col1, col2)\n",
    "        insight = explain(res)\n",
    "        save_result('Chi-Square Test', text=res, insight=insight)\n",
    "\n",
    "    else:\n",
    "        summary = run_regression(df, col1, [col2])\n",
    "        save_result('Regression', text=str(summary))\n",
    "\n",
    "# Tampilkan hasil analisis\n",
    "show_result_inline('Statistical Test')\n",
    "show_result_inline('Chi-Square Test')\n",
    "show_result_inline('Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535b5bf7",
   "metadata": {},
   "source": [
    "## 6. Trend Analysis (Time-Series)\n",
    "Displays trends based on date columns and numeric values, with aggregation (mean, sum, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1299ff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trend(df, date_col, val_col, agg_func, sort_order):\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[date_col]):\n",
    "        df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "    df[date_col] = df[date_col].dt.floor('D')\n",
    "    agg_df = df.groupby(date_col)[val_col].agg(agg_func).sort_values(\n",
    "        ascending=(sort_order == \"Ascending\")\n",
    "    )\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    sns.lineplot(x=agg_df.index, y=agg_df.values, ax=ax, color=\"teal\", marker=\"o\")\n",
    "    ax.set_title(f\"Trend of {val_col} by Date ({agg_func})\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(val_col)\n",
    "    plt.xticks(rotation=45)\n",
    "    return agg_df, fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bac638",
   "metadata": {},
   "source": [
    "## 7. Categorical Aggregation\n",
    "Displays the average, count, or sum by category, visualized as a barplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b20804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_categorical(df, cat_col, val_col, agg_func, sort_order):\n",
    "    ascending = (sort_order == \"Lowest\")\n",
    "    agg_df = df.groupby(cat_col)[val_col].agg(agg_func).sort_values(ascending=ascending)\n",
    "    fig, ax = plt.subplots(figsize=(10,4))\n",
    "    sns.barplot(x=agg_df.index, y=agg_df.values, ax=ax, palette=\"viridis\")\n",
    "    ax.set_title(f\"{agg_func.title()} by {cat_col}\")\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    return agg_df, fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5296d7b1",
   "metadata": {},
   "source": [
    "## 8. Q&A (AI Insight)\n",
    "Using GPT to explain results or provide business action recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5689fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain(text, question=None):\n",
    "    if not openai_key: return \"No API key.\"\n",
    "    openai.api_key = openai_key\n",
    "    prompt = f\"Jelaskan hasil statistik ini untuk tim non-teknis:\\n{text}\"\n",
    "    if question:\n",
    "        prompt += f\"\\nJawab pertanyaan: {question}\"\n",
    "    res = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\":\"user\",\"content\":prompt}],\n",
    "        temperature=0.4\n",
    "    )\n",
    "    return res.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b61b869",
   "metadata": {},
   "source": [
    "## 9. Export to PDF\n",
    "All analysis results and visualizations can be exported to PDF for reporting purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aa4186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_pdf(results_dict):\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    pdf.set_font(\"Arial\", size=12)\n",
    "    pdf.multi_cell(0, 10, \"Analysis Report\")\n",
    "\n",
    "    for section, content in results_dict.items():\n",
    "        pdf.ln(5)\n",
    "        pdf.set_font(\"Arial\", \"B\", 14)\n",
    "        pdf.cell(0, 10, section, ln=True)\n",
    "        pdf.set_font(\"Arial\", size=11)\n",
    "\n",
    "        if isinstance(content, tuple):\n",
    "            text = content[0] if len(content) > 0 else \"\"\n",
    "            insight = content[1] if len(content) > 1 else \"\"\n",
    "            fig = content[2] if len(content) > 2 else None\n",
    "\n",
    "            pdf.multi_cell(0, 8, text)\n",
    "            if insight:\n",
    "                pdf.multi_cell(0, 8, \"\\nInsights:\\n\" + insight)\n",
    "            if fig and isinstance(fig, plt.Figure):\n",
    "                with tempfile.NamedTemporaryFile(delete=False, suffix=\".png\") as tmp_img:\n",
    "                    fig.savefig(tmp_img.name, bbox_inches=\"tight\")\n",
    "                    tmp_img.flush()\n",
    "                    pdf.ln(5)\n",
    "                    pdf.image(tmp_img.name, w=170)\n",
    "        else:\n",
    "            pdf.multi_cell(0, 8, str(content))\n",
    "\n",
    "    tmp_pdf = tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\")\n",
    "    pdf.output(tmp_pdf.name)\n",
    "    return tmp_pdf.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92a010c",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "This project demonstrates how to build a modular and interactive data analysis tool using Python, integrating statistical testing, visualization, and AI-powered explanations into a single workflow.\n",
    "\n",
    "Key takeaways:\n",
    "- The app automatically detects the correct statistical test (T-test, Mann-Whitney, ANOVA, Kruskal-Wallis, Chi-Square, or Regression) based on the data types and groupings selected by the user.\n",
    "- Time-series and categorical aggregation modules allow quick exploratory insights beyond hypothesis testing.\n",
    "- Power analysis helps users estimate the minimum sample size before running tests, ensuring statistical validity.\n",
    "- The system leverages OpenAI's API to translate statistical outputs into plain language insights, helping non technical stakeholders understand the results.\n",
    "- Users can export all results, figures, and interpretations into a single PDF report, making it suitable for presentations and decision-making.\n",
    "\n",
    "Overall, this project serves as both a **portfolio piece** and a **practical tool** for exploratory data analysis and hypothesis testing.  \n",
    "It can be extended by adding:\n",
    "- Support for multi-variable regression and interaction terms.\n",
    "- Automated A/B testing dashboards.\n",
    "- Integration with databases (SQL) or cloud-based storage.\n",
    "- More AI-driven recommendations (e.g., automatic business action suggestions).\n",
    "\n",
    "This notebook not only showcases technical implementation but also bridges the gap between **raw statistical analysis** and **decision-ready insights**.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
